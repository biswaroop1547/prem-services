name: CI

env:
  DOCKER_BUILDKIT: 1
  DOCKER_CLI_EXPERIMENTAL: "enabled"
  COMPOSE_DOCKER_CLI_BUILD: 1

on:
  pull_request:
    branches: ["main"]

  push:
    branches: ["main"]

jobs:
  linter:
    runs-on: gpu
    steps:
      - name: Checkout Code Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Run pre-commit
        uses: pre-commit/action@v3.0.0

  build-cpu:
    runs-on: gpu
    needs: [linter]
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v1

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v2
        with:
          install: true

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build the images
        run: |
          docker buildx build --file ./chat-llama-cpp/docker/cpu/Dockerfile --build-arg="MODEL_ID=vicuna-7b-q4" --tag ghcr.io/premai-io/chat-vicuna-7b-q4-cpu:latest --platform linux/arm64,linux/amd64 ./chat-llama-cpp
          docker buildx build --file ./chat-llama-cpp/docker/cpu/Dockerfile --build-arg="MODEL_ID=gpt4all-lora-q4" --tag ghcr.io/premai-io/chat-gpt4all-lora-q4-cpu:latest --platform linux/arm64,linux/amd64 ./chat-llama-cpp
          docker buildx build --file ./embeddings-st/docker/cpu/Dockerfile --build-arg="MODEL_ID=sentence-transformers/all-MiniLM-L6-v2" --tag ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-cpu:latest --platform linux/arm64,linux/amd64 ./embeddings-st
          docker buildx build --file ./audio-to-text-wh/docker/cpu/Dockerfile --build-arg="MODEL_ID=tiny" --tag ghcr.io/premai-io/audio-to-text-whisper-tiny-cpu:latest --platform linux/arm64,linux/amd64 ./audio-to-text-wh
          docker buildx build --file ./text-to-audio-ba/docker/cpu/Dockerfile --tag ghcr.io/premai-io/text-to-audio-bark-cpu:latest --platform linux/arm64,linux/amd64 ./text-to-audio-ba
          docker buildx build --file ./copilot-t5/docker/cpu/Dockerfile --build-arg="MODEL_ID=Salesforce/codet5p-220m-py" --tag ghcr.io/premai-io/copilot-codet5p-220m-py-cpu:latest --platform linux/arm64,linux/amd64 ./copilot-t5
          docker buildx build --file ./michelangelo-sd/docker/cpu/Dockerfile --build-arg="MODEL_ID=stabilityai/stable-diffusion-2-1-base" --tag ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-cpu:latest --platform linux/arm64,linux/amd64 ./michelangelo-sd
          docker buildx build --file ./michelangelo-sd/docker/cpu/Dockerfile --build-arg="MODEL_ID=stabilityai/stable-diffusion-2-base" --tag ghcr.io/premai-io/michelangelo-stable-diffusion-2-base-cpu:latest --platform linux/arm64,linux/amd64 ./michelangelo-sd

  test-cpu:
    runs-on: gpu
    needs: [build-cpu]
    steps:
      - name: Checkout Code Repository
        uses: actions/checkout@v3

      - name: Test images for CPU devices
        run: |
          docker run --rm ghcr.io/premai-io/chat-vicuna-7b-q4-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/audio-to-text-whisper-tiny-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/text-to-audio-bark-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/copilot-codet5p-220m-py-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-cpu:latest pytest
          docker run --rm ghcr.io/premai-io/michelangelo-stable-diffusion-2-base-cpu:latest pytest

  push-cpu:
    runs-on: gpu
    needs: [test-cpu]
    permissions:
      contents: read
      packages: write
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v2

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v1

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v2
        with:
          install: true

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Push the Images
        run: |
          docker push ghcr.io/premai-io/chat-vicuna-7b-q4-cpu:latest
          docker push ghcr.io/premai-io/chat-gpt4all-lora-q4-cpu:latest
          docker push ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-cpu:latest
          docker push ghcr.io/premai-io/audio-to-text-whisper-tiny-cpu:latest
          docker push ghcr.io/premai-io/text-to-audio-bark-cpu:latest
          docker push ghcr.io/premai-io/copilot-codet5p-220m-py-cpu:latest
          docker push ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-cpu:latest
          docker push ghcr.io/premai-io/michelangelo-stable-diffusion-2-base-cpu:latest

  build-gpu:
    runs-on: gpu
    needs: [linter]
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v1

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v2
        with:
          install: true

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and Push the Images
        run: |
          docker buildx build --push --file ./chat-dolly-v2/docker/gpu/Dockerfile --build-arg="MODEL_ID=databricks/dolly-v2-12b" --tag ghcr.io/premai-io/chat-dolly-v2-12b-gpu:latest --platform linux/arm64,linux/amd64 ./chat-dolly-v2
          docker buildx build --push --file ./embeddings-st/docker/gpu/Dockerfile --build-arg="MODEL_ID=sentence-transformers/all-MiniLM-L6-v2" --tag ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-gpu:latest --platform linux/arm64,linux/amd64 ./embeddings-st
          docker buildx build --push --file ./audio-to-text-wh/docker/gpu/Dockerfile --build-arg="MODEL_ID=large-v2" --tag ghcr.io/premai-io/audio-to-text-whisper-large-v2-gpu:latest --platform linux/arm64,linux/amd64 ./audio-to-text-wh
          docker buildx build --push --file ./text-to-audio-ba/docker/gpu/Dockerfile --tag ghcr.io/premai-io/text-to-audio-bark-gpu:latest --platform linux/arm64,linux/amd64 ./text-to-audio-ba
          docker buildx build --push --file ./copilot-replit/docker/gpu/Dockerfile --build-arg="MODEL_ID=replit/replit-code-v1-3b" --tag ghcr.io/premai-io/copilot-replit-code-v1-3b-gpu:latest --platform linux/arm64,linux/amd64 ./copilot-replit
          docker buildx build --push --file ./michelangelo-sd/docker/gpu/Dockerfile --build-arg="MODEL_ID=stabilityai/stable-diffusion-2-1-base" --tag ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-gpu:latest --platform linux/arm64,linux/amd64 ./michelangelo-sd
          docker buildx build --push --file ./michelangelo-sd/docker/gpu/Dockerfile --build-arg="MODEL_ID=stabilityai/stable-diffusion-2-base" --tag ghcr.io/premai-io/michelangelo-stable-diffusion-2-base-gpu:latest --platform linux/arm64,linux/amd64 ./michelangelo-sd

  test-gpu:
    runs-on: gpu
    needs: [build-gpu]
    steps:
      - name: Checkout Code Repository
        uses: actions/checkout@v3

      - name: Build and Test the Images for Mac M1 devices
        run: |
          docker run --rm --gpus all ghcr.io/premai-io/chat-dolly-v2-12b-gpu:latest pytest
          docker run --rm --gpus all ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-gpu:latest pytest
          docker run --rm --gpus all ghcr.io/premai-io/audio-to-text-whisper-large-v2-gpu:latest pytest
          docker run --rm --gpus all ghcr.io/premai-io/text-to-audio-bark-gpu:latest pytest
          docker run --rm --gpus all ghcr.io/premai-io/copilot-replit-code-v1-3b-gpu:latest pytest
          docker run --rm --gpus all ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-gpu:latest pytest

  push-gpu:
    runs-on: gpu
    needs: [test-gpu]
    permissions:
      contents: read
      packages: write
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v2

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v1

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v2
        with:
          install: true

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Push the Images
        run: |
          docker push ghcr.io/premai-io/chat-dolly-v2-12b-gpu:latest
          docker push ghcr.io/premai-io/embeddings-all-MiniLM-L6-v2-gpu:latest
          docker push ghcr.io/premai-io/audio-to-text-whisper-tiny-gpu:latest
          docker push ghcr.io/premai-io/text-to-audio-bark-gpu:latest
          docker push ghcr.io/premai-io/copilot-codet5p-220m-py-gpu:latest
          docker push ghcr.io/premai-io/michelangelo-stable-diffusion-2-1-base-gpu:latest
          docker push ghcr.io/premai-io/michelangelo-stable-diffusion-2-base-gpu:latest
