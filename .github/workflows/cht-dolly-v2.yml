name: Chat Dolly V2

env:
  DOCKER_BUILDKIT: 1
  DOCKER_CLI_EXPERIMENTAL: "enabled"
  COMPOSE_DOCKER_CLI_BUILD: 1

on:
  pull_request:
    branches: ["main"]

  push:
    branches: ["main"]
    paths:
      - "cht-dolly-v2/**"

jobs:
    deploy-cht-dolly-v2:
        runs-on: gpu
        permissions:
            contents: read
            packages: write
        steps:
        - uses: actions/checkout@v2

        - name: Set up QEMU
          uses: docker/setup-qemu-action@v1

        - name: Set up Docker Buildx
          id: buildx
          uses: docker/setup-buildx-action@v2
          with:
            install: true

        - name: Login to GitHub Container Registry
          uses: docker/login-action@v2
          with:
            registry: ghcr.io
            username: ${{ github.repository_owner }}
            password: ${{ secrets.GITHUB_TOKEN }}

        - name: Test the Images
          run: |
            docker build --file ./cht-dolly-v2/docker/gpu/Dockerfile --build-arg="MODEL_ID=tiny" --tag cht-dolly-v2 ./cht-dolly-v2
            docker run --rm --gpus all cht-dolly-v2 pytest

        - name: Build and Push
          run: docker buildx build --push --file ./cht-dolly-v2/docker/gpu/Dockerfile --build-arg="MODEL_ID=databricks/dolly-v2-12b" --tag ghcr.io/premai-io/chat-dolly-v2-12b-gpu:latest --platform linux/arm64,linux/amd64 ./chat-dolly-v2
